{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e580caf8",
   "metadata": {},
   "source": [
    "### Required dependencies\n",
    "You'll need recent versions of Jupyter (but if you're reading this, you are probably OK), scikit-learn, numpy, pandas and matplotlib and/or seaborn. The most recent versions should be fine. You are free to use any other package under the sun, but I suspect you will be at least needing the above.\n",
    "\n",
    "I advise you to use a form of virtual environments to manage your python projects (e.g. pipenv, venv, conda etc.).\n",
    "\n",
    "To get free GPU time, you can try Google Colab. It is a tool for running notebooks like this on the fly, and provides you with a VM and a GPU for free. Almost all packages for machine learning are automatically installed, and I suspect you could the entire project on Colab if you wanted to. Still, it is useful to learn how to set up your environment on your own pc as well, and Colab is a bit more complicated when you have to import your datasets (best to import them from a Google Drive for speed). Colab could become useful if you intend to try the deep learning approaches with TensorFlow and PyTorch, and you don't have a GPU yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b5999c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical library:\n",
    "import numpy as np\n",
    "\n",
    "# data manipulation library:\n",
    "import pandas as pd\n",
    "\n",
    "# standard packages used to handle files:\n",
    "import sys\n",
    "import os \n",
    "import glob\n",
    "import time\n",
    "\n",
    "# scikit-learn machine learning library:\n",
    "import sklearn\n",
    "\n",
    "# plotting:\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm as cm\n",
    "from matplotlib import patches\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import PowerTransformer,FunctionTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error,make_scorer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "\n",
    "# tell matplotlib that we plot in a notebook:\n",
    "# %matplotlib notebook"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d8ce32fd",
   "metadata": {},
   "source": [
    "Define your folder structure with your data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d929682f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"./\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b8c8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(data_folder + \"train.csv\")\n",
    "test_data = pd.read_csv(data_folder + \"test.csv\")\n",
    "\n",
    "# Drop the date column from test\n",
    "# test_data = test_data.drop([\"date\"], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bd3cae93",
   "metadata": {},
   "source": [
    "### Data exploration\n",
    "Let's take a look at our train and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4943a9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0771c506",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c6bfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "34e6313f",
   "metadata": {},
   "source": [
    "Let's take a look at our first 1000 datapoints in the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a5c0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d553822c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_temp = train_data.copy()\n",
    "# Drop the date column\n",
    "train_data_temp = train_data_temp.drop([\"date\"], axis=1)\n",
    "train_data_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d764b640",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_temp.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2568f4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lights , T2,T3 T6,RH_out are high corelated with Appliances\n",
    "train_data_temp.corrwith(train_data_temp[\"Appliances\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f669ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T_out and T6 high corelation \n",
    "corr_matrix = train_data_temp.corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82b8af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(corr_matrix, annot=False, fmt=\".2f\", square=True, cmap='RdBu_r')  \n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_temp.hist(figsize=(10, 10))\n",
    "\n",
    "# RH_out light are skewed T1,RH_1,T2,RH2 data are normaly distributed\n",
    "# Plot histograms with a specified layout and size\n",
    "train_data_temp.hist(bins=50, figsize=(15, 15))\n",
    "\n",
    "# Add margins around each histogram using subplots_adjust\n",
    "plt.subplots_adjust(bottom=0.1, top=0.9, left=0.1, right=0.9, wspace=0.4, hspace=0.4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "68d1482e",
   "metadata": {},
   "source": [
    "## Lights\n",
    "On average 60 Wh light is high, when the energy usage of the lights is 60 Wh (watt-hours), the energy usage of the appliances in the house is around 600 Wh.\n",
    "\n",
    "However, this does not mean that the light fixtures themselves are high energy consumers or that they are directly responsible for the energy usage of the appliances. lights and Appliances are measurements of different systems within the house."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085fd2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_temp.loc[:, [\"lights\", \"Appliances\"]].groupby(\"lights\").mean().plot.bar()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7b080e73",
   "metadata": {},
   "source": [
    "## T1\n",
    "\n",
    "T1, Temperature in kitchen area, in Celsius\n",
    "\n",
    "When the kitchen temperature T1 is colder around 16-17 degrees Celsius the average energy consumption of appliances tends to be higher (around 140 Wh). This might be because heating appliances or others like ovens are used more. On the other hand, when the kitchen is warmer around 22-23 degrees Celsius, the average energy consumption of appliances decreases to around 120 Wh, possibly because heating appliances are used less or other appliances are used more efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a285b5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_T1 = train_data_temp['T1'].min()\n",
    "max_T1 = train_data_temp['T1'].max()\n",
    "\n",
    "print(f\"Minimum value of T1: {min_T1}\")\n",
    "print(f\"Maximum value of T1: {max_T1}\")\n",
    "\n",
    "# Bin edges.\n",
    "bin_edges = np.arange(16, 25, 1) # Fixed bin size of 1\n",
    "# Bin the data into discrete intervals.\n",
    "train_data_temp['T1_binned'] = pd.cut(train_data_temp['T1'], bins=bin_edges)\n",
    "\n",
    "# Average Appliances energy use for each bin.\n",
    "train_data_temp.loc[:, [\"T1_binned\", \"Appliances\"]].groupby(\"T1_binned\").mean().plot.bar()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "98385784",
   "metadata": {},
   "source": [
    "## RH_1\n",
    "\n",
    "RH_1, Humidity in kitchen area, in %\n",
    "\n",
    "When the kitchen humidity is lower (27-29%), appliances use more energy (175 Wh). When it's more humid (57-59%), they use less energy (100 Wh).\n",
    "\n",
    "This could be due to various factors, such as increased use of dehumidifiers or air conditioning, or changes in how other appliances perform under these conditions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5520e6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_RH_1 = train_data_temp['RH_1'].min()\n",
    "max_RH_1 = train_data_temp['RH_1'].max()\n",
    "\n",
    "print(f\"Minimum value of RH_1: {min_RH_1}\")\n",
    "print(f\"Maximum value of RH_1: {max_RH_1}\")\n",
    "\n",
    "bin_edges = np.arange(27, 63, 2) \n",
    "train_data_temp['RH_1_binned'] = pd.cut(train_data_temp['RH_1'], bins=bin_edges)\n",
    "\n",
    "train_data_temp.loc[:, [\"RH_1_binned\", \"Appliances\"]].groupby(\"RH_1_binned\").mean().plot.bar()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T2\n",
    "\n",
    "T2, Temperature in living room area, in Celsius\n",
    "\n",
    "When the temperature between 16-18 degrees appliances use less energy around 70-80 Wh. This might be because less energy needed for heating or cooling. However when the temperature increases to between 22-23 degrees the energy usage of appliances increases to about 150 Wh. This could be due to increased use of cooling appliances like air conditioners or fans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71245df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_T2 = train_data_temp['T2'].min()\n",
    "max_T2 = train_data_temp['T2'].max()\n",
    "\n",
    "print(f\"Minimum value of T2: {min_T2}\")\n",
    "print(f\"Maximum value of T2: {max_T2}\")\n",
    "\n",
    "bin_edges = np.arange(16, 24, 1)\n",
    "train_data_temp['T2_binned'] = pd.cut(train_data_temp['T2'], bins=bin_edges)\n",
    "\n",
    "train_data_temp.loc[:, [\"T2_binned\", \"Appliances\"]].groupby(\"T2_binned\").mean().plot.bar()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9a5669b2",
   "metadata": {},
   "source": [
    "## RH_2\n",
    "\n",
    "RH_2, Humidity in living room area, in %\n",
    "\n",
    "As humidity in the living room changes from low (25-30%) to moderate (45-50%) to high (50-55%) appliance energy usage first decreases from 175 Wh to 100 Wh then increases back up to 200 Wh possibly indicating the use of appliances to manage excessive humidity such as air conditioners or dehumidifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6ba770",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_RH_2 = train_data_temp['RH_2'].min()\n",
    "max_RH_2 = train_data_temp['RH_2'].max()\n",
    "\n",
    "print(f\"Minimum value of RH_2: {min_RH_2}\")\n",
    "print(f\"Maximum value of RH_2: {max_RH_2}\")\n",
    "\n",
    "bin_edges = np.arange(25, 56, 5)\n",
    "train_data_temp['RH_2_binned'] = pd.cut(train_data_temp['RH_2'], bins=bin_edges)\n",
    "\n",
    "train_data_temp.loc[:, [\"RH_2_binned\", \"Appliances\"]].groupby(\"RH_2_binned\").mean().plot.bar()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ac17056",
   "metadata": {},
   "source": [
    "## T3\n",
    "\n",
    "T3, Temperature in laundry room area\n",
    "\n",
    "As the temperature in the laundry room increases for example from 50 to 55 degrees Celsius, the energy usage of appliances also increases to around 200 Wh, potentially indicating more use of appliances like washers or dryers in warmer conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb042bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_T3 = train_data_temp['T3'].min()\n",
    "max_T3 = train_data_temp['T3'].max()\n",
    "\n",
    "print(f\"Minimum value of T3: {min_T3}\")\n",
    "print(f\"Maximum value of T3: {max_T3}\")\n",
    "\n",
    "bin_edges = np.arange(17, 27, 1)\n",
    "train_data_temp['T3_binned'] = pd.cut(train_data_temp['T3'], bins=bin_edges)\n",
    "\n",
    "train_data_temp.loc[:, [\"T3_binned\", \"Appliances\"]].groupby(\"T3_binned\").mean().plot.bar()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "27a736b2",
   "metadata": {},
   "source": [
    "## RH_3\n",
    "\n",
    "RH_3, Humidity in laundry room area, in %\n",
    "\n",
    "As the humidity in the laundry room increases from around 32%-34% to 46%-48% the average energy usage of appliances also rises from approximately 120 Wh to 140 Wh. This suggests that higher humidity levels could be associated with increased use or efficiency of certain appliances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b61cee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_RH_3 = train_data_temp['RH_3'].min()\n",
    "max_RH_3 = train_data_temp['RH_3'].max()\n",
    "\n",
    "print(f\"Minimum value of RH_3: {min_RH_3}\")\n",
    "print(f\"Maximum value of RH_3: {max_RH_3}\")\n",
    "\n",
    "bin_edges = np.arange(32, 50, 2)\n",
    "train_data_temp['RH_3_binned'] = pd.cut(train_data_temp['RH_3'], bins=bin_edges)\n",
    "\n",
    "train_data_temp.loc[:, [\"RH_3_binned\", \"Appliances\"]].groupby(\"RH_3_binned\").mean().plot.bar()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fd011f61",
   "metadata": {},
   "source": [
    "## T4\n",
    "\n",
    "T4, Temperature in office room, in Celsius\n",
    "\n",
    "As the office room temperature rises from 15-16°C to 21-22°C, the energy consumption by appliances increases from 70 Wh to 120 Wh. This implies that higher temperatures might cause higher energy usage by the appliances in the office room.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd5c7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_T4 = train_data_temp['T4'].min()\n",
    "max_T4 = train_data_temp['T4'].max()\n",
    "\n",
    "print(f\"Minimum value of T4: {min_T4}\")\n",
    "print(f\"Maximum value of T4: {max_T4}\")\n",
    "\n",
    "bin_edges = np.arange(15, 23, 1)\n",
    "train_data_temp['T4_binned'] = pd.cut(train_data_temp['T4'], bins=bin_edges)\n",
    "\n",
    "train_data_temp.loc[:, [\"T4_binned\", \"Appliances\"]].groupby(\"T4_binned\").mean().plot.bar()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fbacac86",
   "metadata": {},
   "source": [
    "## RH_4\n",
    "\n",
    "RH_4, Humidity in office room, in %\n",
    "\n",
    "In the office room, as humidity levels rise from 27-30% to 45-48%, the energy usage by appliances decreases from 150 Wh to 85 Wh. This suggests that appliances in the office room might use less energy when the humidity is higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f835c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_RH_4 = train_data_temp['RH_4'].min()\n",
    "max_RH_4 = train_data_temp['RH_4'].max()\n",
    "\n",
    "print(f\"Minimum value of RH_4: {min_RH_4}\")\n",
    "print(f\"Maximum value of RH_4: {max_RH_4}\")\n",
    "\n",
    "bin_edges = np.arange(27, 51, 3)\n",
    "train_data_temp['RH_4_binned'] = pd.cut(train_data_temp['RH_4'], bins=bin_edges)\n",
    "\n",
    "train_data_temp.loc[:, [\"RH_4_binned\", \"Appliances\"]].groupby(\"RH_4_binned\").mean().plot.bar()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9c441356",
   "metadata": {},
   "source": [
    "## T5\n",
    "\n",
    "T5, Temperature in bathroom, in Celsius\n",
    "\n",
    "In the bathroom, when the temperature is between 16-17 degrees Celsius, the energy usage by appliances is the lowest at 65 Wh. However, when the temperature is either lower 15-16 degrees or higher 19-21 degrees the energy usage increases, with the highest being 110 Wh at 20-21 degrees Celsius.The change in energy use of appliances with bathroom temperature may be due to increased use of heating or cooling devices during colder or warmer temperatures respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14fdb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_T5 = train_data_temp['T5'].min()\n",
    "max_T5 = train_data_temp['T5'].max()\n",
    "\n",
    "print(f\"Minimum value of T5: {min_T5}\")\n",
    "print(f\"Maximum value of T5: {max_T5}\")\n",
    "\n",
    "bin_edges = np.arange(15, 22, 1)\n",
    "train_data_temp['T5_binned'] = pd.cut(train_data_temp['T5'], bins=bin_edges)\n",
    "\n",
    "train_data_temp.loc[:, [\"T5_binned\", \"Appliances\"]].groupby(\"T5_binned\").mean().plot.bar()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "390500cc",
   "metadata": {},
   "source": [
    "## RH_5\n",
    "\n",
    "RH_5, Humidity in bathroom, in %\n",
    "\n",
    "The energy usage of appliances varies with humidity in the bathroom, dropping at mid-ranges but increasing again at high and low levels, suggesting appliances might be used more when the humidity is either very low or high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0920a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_RH_5 = train_data_temp['RH_5'].min()\n",
    "max_RH_5 = train_data_temp['RH_5'].max()\n",
    "\n",
    "print(f\"Minimum value of RH_5: {min_RH_5}\")\n",
    "print(f\"Maximum value of RH_5: {max_RH_5}\")\n",
    "\n",
    "bin_edges = np.arange(35, 96, 5)\n",
    "train_data_temp['RH_5_binned'] = pd.cut(train_data_temp['RH_5'], bins=bin_edges)\n",
    "\n",
    "train_data_temp.loc[:, [\"RH_5_binned\", \"Appliances\"]].groupby(\"RH_5_binned\").mean().plot.bar()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "48a86378",
   "metadata": {},
   "source": [
    "## T6\n",
    "\n",
    "T6, Temperature outside the building (north side), in Celsius\n",
    "\n",
    "As the outside temperature increases, the energy usage of appliances tends to increase as well, possibly due to the increased use of cooling systems or other temperature-regulating appliances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff272578",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_T6 = train_data_temp['T6'].min()\n",
    "max_T6 = train_data_temp['T6'].max()\n",
    "\n",
    "print(f\"Minimum value of T6: {min_T6}\")\n",
    "print(f\"Maximum value of T6: {max_T6}\")\n",
    "\n",
    "bin_edges = np.arange(-6, 21, 3)\n",
    "train_data_temp['T6_binned'] = pd.cut(train_data_temp['T6'], bins=bin_edges)\n",
    "\n",
    "train_data_temp.loc[:, [\"T6_binned\", \"Appliances\"]].groupby(\"T6_binned\").mean().plot.bar()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6137af28",
   "metadata": {},
   "source": [
    "## RH_6\n",
    "\n",
    "RH_6, Humidity outside the building (north side), in %\n",
    "\n",
    "The energy usage of appliances fluctuates with the outside humidity initially it decreases as humidity increases to around 51%, then it rises until humidity hits 81%, after which it decreases again, possibly indicating different energy needs under varying humidity levels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945475b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_RH_6 = train_data_temp['RH_6'].min()\n",
    "max_RH_6 = train_data_temp['RH_6'].max()\n",
    "\n",
    "print(f\"Minimum value of RH_6: {min_RH_6}\")\n",
    "print(f\"Maximum value of RH_6: {max_RH_6}\")\n",
    "\n",
    "bin_edges = np.arange(1, 99, 10)\n",
    "train_data_temp['RH_6_binned'] = pd.cut(train_data_temp['RH_6'], bins=bin_edges)\n",
    "\n",
    "train_data_temp.loc[:, [\"RH_6_binned\", \"Appliances\"]].groupby(\"RH_6_binned\").mean().plot.bar()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5749df76",
   "metadata": {},
   "source": [
    "## T7\n",
    "\n",
    "T7, Temperature in ironing room , in Celsius\n",
    "\n",
    "\n",
    "As the temperature in the ironing room increases from 15 degrees to 24 degrees Celsius, the energy usage of appliances generally tends to increase, suggesting that higher temperatures in the room might correspond to increased appliance activity or energy use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7830289b",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_T7 = train_data_temp['T7'].min()\n",
    "max_T7 = train_data_temp['T7'].max()\n",
    "\n",
    "print(f\"Minimum value of T7: {min_T7}\")\n",
    "print(f\"Maximum value of T7: {max_T7}\")\n",
    "\n",
    "bin_edges = np.arange(15, 25, 1)\n",
    "train_data_temp['T7_binned'] = pd.cut(train_data_temp['T7'], bins=bin_edges)\n",
    "\n",
    "train_data_temp.loc[:, [\"T7_binned\", \"Appliances\"]].groupby(\"T7_binned\").mean().plot.bar()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7f27001e",
   "metadata": {},
   "source": [
    "## RH_7\n",
    "\n",
    "RH_7, Humidity in ironing room, in %\n",
    "\n",
    "While appliance energy usage is high at 23-26% humidity in the ironing room, it drops to around 100 Wh for other humidity levels, suggesting that except for this specific humidity range, the humidity level doesn't significantly affect the appliance energy usage in the ironing room."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa475cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_RH_7 = train_data_temp['RH_7'].min()\n",
    "max_RH_7 = train_data_temp['RH_7'].max()\n",
    "\n",
    "print(f\"Minimum value of RH_7: {min_RH_7}\")\n",
    "print(f\"Maximum value of RH_7: {max_RH_7}\")\n",
    "\n",
    "bin_edges = np.arange(23, 51, 3)\n",
    "train_data_temp['RH_7_binned'] = pd.cut(train_data_temp['RH_7'], bins=bin_edges)\n",
    "\n",
    "train_data_temp.loc[:, [\"RH_7_binned\", \"Appliances\"]].groupby(\"RH_7_binned\").mean().plot.bar()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2d60189b",
   "metadata": {},
   "source": [
    "## T8\n",
    "\n",
    "T8, Temperature in teenager room 2, in Celsius\n",
    "\n",
    "\n",
    "In the teenager's room, as the temperature initially rises from 16 to 20 degrees Celsius, the appliance energy usage increases. However, between 20 to 22 degrees, energy usage drops, before it increases again as the temperature rises further, indicating a complex relationship between temperature and energy usage in this room."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991563c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_T8 = train_data_temp['T8'].min()\n",
    "max_T8 = train_data_temp['T8'].max()\n",
    "\n",
    "print(f\"Minimum value of T8: {min_T8}\")\n",
    "print(f\"Maximum value of T8: {max_T8}\")\n",
    "\n",
    "bin_edges = np.arange(16, 25, 1)\n",
    "train_data_temp['T8_binned'] = pd.cut(train_data_temp['T8'], bins=bin_edges)\n",
    "\n",
    "train_data_temp.loc[:, [\"T8_binned\", \"Appliances\"]].groupby(\"T8_binned\").mean().plot.bar()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "63321ed4",
   "metadata": {},
   "source": [
    "## RH_8\n",
    "\n",
    "RH_8, Humidity in teenager room 2, in %\n",
    "\n",
    "For the teenager's room, higher humidity levels 29-35% lead to greater energy usage. However, as humidity continues to rise above 35%, the energy usage starts to drop, reaching a low at 53-56%. This suggests that more energy is consumed to maintain comfort at moderate humidity levels, but less energy is needed at very high humidity levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0682bae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_RH_8 = train_data_temp['RH_8'].min()\n",
    "max_RH_8 = train_data_temp['RH_8'].max()\n",
    "\n",
    "print(f\"Minimum value of RH_8: {min_RH_8}\")\n",
    "print(f\"Maximum value of RH_8: {max_RH_8}\")\n",
    "\n",
    "bin_edges = np.arange(29, 58, 3)\n",
    "train_data_temp['RH_8_binned'] = pd.cut(train_data_temp['RH_8'], bins=bin_edges)\n",
    "\n",
    "train_data_temp.loc[:, [\"RH_8_binned\", \"Appliances\"]].groupby(\"RH_8_binned\").mean().plot.bar()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1f90a4ed",
   "metadata": {},
   "source": [
    "## T9\n",
    "\n",
    "T9, Temperature in parents room, in Celsius\n",
    "\n",
    "\n",
    "In the parents' room, energy consumption for appliances initially decreases with increasing temperature from 14 to 17 degrees Celsius. However, when the temperature rises to 21-22 degrees Celsius, the energy consumption significantly increases to 160 Wh, possibly indicating increased use of cooling appliances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8376d607",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_T9 = train_data_temp['T9'].min()\n",
    "max_T9 = train_data_temp['T9'].max()\n",
    "\n",
    "print(f\"Minimum value of T9: {min_T9}\")\n",
    "print(f\"Maximum value of T9: {max_T9}\")\n",
    "\n",
    "bin_edges = np.arange(14, 23, 1)\n",
    "train_data_temp['T9_binned'] = pd.cut(train_data_temp['T9'], bins=bin_edges)\n",
    "\n",
    "train_data_temp.loc[:, [\"T9_binned\", \"Appliances\"]].groupby(\"T9_binned\").mean().plot.bar()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9871a68b",
   "metadata": {},
   "source": [
    "## RH_9\n",
    "\n",
    "RH_9, Humidity in parents room, in %\n",
    "\n",
    "In the parents' room, when the humidity level is between 31-33% the energy consumption of appliances reaches a peak of 140 Wh while at other humidity levels energy usage remains relatively consistent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8477a00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_RH_9 = train_data_temp['RH_9'].min()\n",
    "max_RH_9 = train_data_temp['RH_9'].max()\n",
    "\n",
    "print(f\"Minimum value of RH_9: {min_RH_9}\")\n",
    "print(f\"Maximum value of RH_9: {max_RH_9}\")\n",
    "\n",
    "bin_edges = np.arange(31, 53, 2)\n",
    "train_data_temp['RH_9_binned'] = pd.cut(train_data_temp['RH_9'], bins=bin_edges)\n",
    "\n",
    "train_data_temp.loc[:, [\"RH_9_binned\", \"Appliances\"]].groupby(\"RH_9_binned\").mean().plot.bar()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "39824606",
   "metadata": {},
   "source": [
    "## T_out\n",
    "\n",
    "T_out, Temperature outside (from weather station), in Celsius\n",
    "\n",
    "When the outside temperature is between -5 and -2 degrees Celsius appliance energy usage is around 80 Wh. As the temperature rises to between 13 and 16 degrees Celsius appliance energy usage peaks at 140 Wh. However once the temperature reaches 16 to 19 degrees Celsius energy consumption decreases to around 90 Wh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ba981e",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_T_out = train_data_temp['T_out'].min()\n",
    "max_T_out = train_data_temp['T_out'].max()\n",
    "\n",
    "print(f\"Minimum value of T_out: {min_T_out}\")\n",
    "print(f\"Maximum value of T_out: {max_T_out}\")\n",
    "\n",
    "bin_edges = np.arange(-5, 20, 3)\n",
    "train_data_temp['T_out_binned'] = pd.cut(train_data_temp['T_out'], bins=bin_edges)\n",
    "\n",
    "train_data_temp.loc[:, [\"T_out_binned\", \"Appliances\"]].groupby(\"T_out_binned\").mean().plot.bar()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4c77eab0",
   "metadata": {},
   "source": [
    "## Press_mm_hg\n",
    "\n",
    "Press_mm_hg (from weather station), in mm Hg\n",
    "\n",
    "When the atmospheric pressure is between 729 and 734 mm Hg, appliance energy usage is around 119 Wh. As the pressure rises to between 734 and 739 mm Hg, appliance energy usage slightly increases to 125 Wh. Then, energy usage decreases a bit until the pressure reaches between 754 and 759 mm Hg, where it starts to increase again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed239085",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_Press_mm_hg = train_data_temp['Press_mm_hg'].min()\n",
    "max_Press_mm_hg = train_data_temp['Press_mm_hg'].max()\n",
    "\n",
    "print(f\"Minimum value of Press_mm_hg: {min_Press_mm_hg}\")\n",
    "print(f\"Maximum value of Press_mm_hg: {max_Press_mm_hg}\")\n",
    "\n",
    "bin_edges = np.arange(729, 772, 5)\n",
    "train_data_temp['Press_mm_hg_binned'] = pd.cut(train_data_temp['Press_mm_hg'], bins=bin_edges)\n",
    "\n",
    "train_data_temp.loc[:, [\"Press_mm_hg_binned\", \"Appliances\"]].groupby(\"Press_mm_hg_binned\").mean().plot.bar()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eaeb5306",
   "metadata": {},
   "source": [
    "## RH_out\n",
    "\n",
    "RH_out, Humidity outside (from weather station), in %\n",
    "\n",
    "When the outside humidity from weather station is between 31% and 36%, the appliance energy usage is around 190 Wh. As the humidity increases to between 36% and 41%, the energy usage drops to 90 Wh. However, when humidity rises further to between 41% and 46%, energy usage spikes again to 180 Wh. Beyond this range, the energy usage fluctuates like a sinusoidal wave with varying humidity levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a897300",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_RH_out = train_data_temp['RH_out'].min()\n",
    "max_RH_out = train_data_temp['RH_out'].max()\n",
    "\n",
    "print(f\"Minimum value of RH_out: {min_RH_out}\")\n",
    "print(f\"Maximum value of RH_out: {max_RH_out}\")\n",
    "\n",
    "bin_edges = np.arange(31, 100, 5)\n",
    "train_data_temp['RH_out_binned'] = pd.cut(train_data_temp['RH_out'], bins=bin_edges)\n",
    "\n",
    "train_data_temp.loc[:, [\"RH_out_binned\", \"Appliances\"]].groupby(\"RH_out_binned\").mean().plot.bar()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dbc4dd1c",
   "metadata": {},
   "source": [
    "## Windspeed\n",
    "\n",
    "Wind speed (from weather station), in m/s\n",
    "\n",
    "The appliance energy usage seems to vary with wind speed when the wind speed is between 0 and 2 m/s energy usage is about 80 Wh at 2 to 4 m/s, it rises to 100 Wh at 4 to 6 m/s, it further increases to 120 Wh. Beyond 6 m/s, energy usage declines until wind speed reaches 8 to 10 m/s, then rises again to 110 Wh when wind speed is between 10 and 12 m/s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f007230c",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_Windspeed = train_data_temp['Windspeed'].min()\n",
    "max_Windspeed = train_data_temp['Windspeed'].max()\n",
    "\n",
    "print(f\"Minimum value of Windspeed: {min_Windspeed}\")\n",
    "print(f\"Maximum value of Windspeed: {max_Windspeed}\")\n",
    "\n",
    "bin_edges = np.arange(0, 14, 2)\n",
    "train_data_temp['Windspeed_binned'] = pd.cut(train_data_temp['Windspeed'], bins=bin_edges)\n",
    "\n",
    "train_data_temp.loc[:, [\"Windspeed_binned\", \"Appliances\"]].groupby(\"Windspeed_binned\").mean().plot.bar()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "05a627e2",
   "metadata": {},
   "source": [
    "## Visibility\n",
    "\n",
    "Visibility (from weather station), in km\n",
    "\n",
    "The appliance energy usage appears to fluctuate with visibility. It starts low at 50 Wh when visibility is between 1 to 6 km then rises as visibility improves up to the range of 36 to 41 km. Beyond this point, energy usage drops back down to 90 Wh when visibility ranges from 41 to 46 km."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027a6f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_Visibility = train_data_temp['Visibility'].min()\n",
    "max_Visibility = train_data_temp['Visibility'].max()\n",
    "\n",
    "print(f\"Minimum value of Visibility: {min_Visibility}\")\n",
    "print(f\"Maximum value of Visibility: {max_Visibility}\")\n",
    "\n",
    "bin_edges = np.arange(1, 66, 5)\n",
    "train_data_temp['Visibility_binned'] = pd.cut(train_data_temp['Visibility'], bins=bin_edges)\n",
    "\n",
    "train_data_temp.loc[:, [\"Visibility_binned\", \"Appliances\"]].groupby(\"Visibility_binned\").mean().plot.bar()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9896bffb",
   "metadata": {},
   "source": [
    "## Tdewpoint\n",
    "\n",
    "Tdewpoint (from weather station), °C\n",
    "\n",
    "The energy usage of appliances seems to be sensitive to the dew point temperature. When the dew point temperature ranges from -6 to -4 degrees Celsius, the energy usage is about 90 Wh. This increases to 120 Wh when the dew point is between -2 to 0 degrees Celsius. Energy usage then decrease until the dew point reaches 6 to 8 degrees Celsius after which it rises again to 100 Wh when the dew point is between 8 to 10 degrees Celsius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6b04f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_Tdewpoint = train_data_temp['Tdewpoint'].min()\n",
    "max_Tdewpoint = train_data_temp['Tdewpoint'].max()\n",
    "\n",
    "print(f\"Minimum value of Tdewpoint: {min_Tdewpoint}\")\n",
    "print(f\"Maximum value of Tdewpoint: {max_Tdewpoint}\")\n",
    "\n",
    "bin_edges = np.arange(-6, 11, 2)\n",
    "train_data_temp['Tdewpoint_binned'] = pd.cut(train_data_temp['Tdewpoint'], bins=bin_edges)\n",
    "\n",
    "train_data_temp.loc[:, [\"Tdewpoint_binned\", \"Appliances\"]].groupby(\"Tdewpoint_binned\").mean().plot.bar()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "095025b1",
   "metadata": {},
   "source": [
    "## rv1\n",
    "\n",
    "rv1, nondimensional\n",
    "\n",
    "The energy usage of appliances does not significantly change with different levels of rv1. Whether rv1 values range from 0 to 5 or from 40 to 45, the energy usage of appliances remains roughly the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46a74e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_rv1 = train_data_temp['rv1'].min()\n",
    "max_rv1 = train_data_temp['rv1'].max()\n",
    "\n",
    "print(f\"Minimum value of rv1: {min_rv1}\")\n",
    "print(f\"Maximum value of rv1: {max_rv1}\")\n",
    "\n",
    "bin_edges = np.arange(0, 49, 5)\n",
    "train_data_temp['rv1_binned'] = pd.cut(train_data_temp['rv1'], bins=bin_edges)\n",
    "\n",
    "train_data_temp.loc[:, [\"rv1_binned\", \"Appliances\"]].groupby(\"rv1_binned\").mean().plot.bar()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff535d4c",
   "metadata": {},
   "source": [
    "## rv2\n",
    "\n",
    "rv2, nondimensional\n",
    "\n",
    "Similar with the rv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf688cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_rv2 = train_data_temp['rv2'].min()\n",
    "max_rv2 = train_data_temp['rv2'].max()\n",
    "\n",
    "print(f\"Minimum value of rv2: {min_rv2}\")\n",
    "print(f\"Maximum value of rv2: {max_rv2}\")\n",
    "\n",
    "bin_edges = np.arange(0, 49, 5)\n",
    "train_data_temp['rv2_binned'] = pd.cut(train_data_temp['rv2'], bins=bin_edges)\n",
    "\n",
    "train_data_temp.loc[:, [\"rv2_binned\", \"Appliances\"]].groupby(\"rv2_binned\").mean().plot.bar()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "84baa3dd",
   "metadata": {},
   "source": [
    "# Feature engineering and encoding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "03a3b9c6",
   "metadata": {},
   "source": [
    "Encoding cyclical continuous features, such as hour of the day, day of the week, or month of the year, into two dimensions using sine and cosine transformations can be useful for certain machine learning algorithms. This is because these algorithms might not inherently understand the cyclical nature of these features.\n",
    "\n",
    "For example, if we're predicting energy usage based on the time of day, the raw numeric encoding can be misleading: 23 (representing 11pm) and 1 (representing 1am) are numerically far apart, even though they are only 2 hours apart in real world. So if we don't encode these cyclical features, the model may learn incorrect associations, such as predicting a significant drop in energy usage from 11pm (23) to 1am (1), when in reality the change may not be significant."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0708940b",
   "metadata": {},
   "source": [
    "*add_cyclical_features* function extracts time features from a date column and encodes them as cyclical features using sin and cos transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6f1080",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cyclical_features(df, date_col='date'):\n",
    "    # Convert the column to datetime type if it's not already\n",
    "    df[date_col] = pd.to_datetime(df[date_col])\n",
    "\n",
    "    # Encode date column\n",
    "    df['Hour'] = df[date_col].dt.hour\n",
    "    df['Day_of_week'] = df[date_col].dt.dayofweek\n",
    "    df['Month'] = df[date_col].dt.month\n",
    "    df['Week_of_year'] = df[date_col].dt.isocalendar().week.astype(\"int64\")\n",
    "\n",
    "    # Encode cyclical features\n",
    "    df['Hour_sin'] = np.sin(2 * np.pi * df['Hour'] / 24)\n",
    "    df['Hour_cos'] = np.cos(2 * np.pi * df['Hour'] / 24)\n",
    "    df['Day_of_week_sin'] = np.sin(2 * np.pi * df['Day_of_week'] / 7)\n",
    "    df['Day_of_week_cos'] = np.cos(2 * np.pi * df['Day_of_week'] / 7)\n",
    "    df['Month_sin'] = np.sin(2 * np.pi * df['Month'] / 12)\n",
    "    df['Month_cos'] = np.cos(2 * np.pi * df['Month'] / 12)\n",
    "    df['Week_of_year_sin'] = np.sin(2 * np.pi * df['Week_of_year'] / 52)\n",
    "    df['Week_of_year_cos'] = np.cos(2 * np.pi * df['Week_of_year'] / 52)\n",
    "    \n",
    "\n",
    "    # Drop the date column\n",
    "    df = df.drop([date_col], axis=1)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a87531d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_training_data = add_cyclical_features(train_data)\n",
    "reshaped_training_data.head()\n",
    "# reshaped_training_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94055409",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_corr_matrix = reshaped_training_data.corr()\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(encoded_corr_matrix, annot=False, fmt=\".2f\", square=True, cmap='RdBu_r')  \n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e73159a2",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1747f96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>lights</th>\n",
       "      <th>T1</th>\n",
       "      <th>RH_1</th>\n",
       "      <th>T2</th>\n",
       "      <th>RH_2</th>\n",
       "      <th>T3</th>\n",
       "      <th>RH_3</th>\n",
       "      <th>T4</th>\n",
       "      <th>RH_4</th>\n",
       "      <th>...</th>\n",
       "      <th>T9</th>\n",
       "      <th>RH_9</th>\n",
       "      <th>T_out</th>\n",
       "      <th>Press_mm_hg</th>\n",
       "      <th>RH_out</th>\n",
       "      <th>Windspeed</th>\n",
       "      <th>Visibility</th>\n",
       "      <th>Tdewpoint</th>\n",
       "      <th>rv1</th>\n",
       "      <th>rv2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-11 17:00:00</td>\n",
       "      <td>30</td>\n",
       "      <td>19.89</td>\n",
       "      <td>47.596667</td>\n",
       "      <td>19.2</td>\n",
       "      <td>44.790000</td>\n",
       "      <td>19.79</td>\n",
       "      <td>44.730000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>45.566667</td>\n",
       "      <td>...</td>\n",
       "      <td>17.033333</td>\n",
       "      <td>45.53</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>733.5</td>\n",
       "      <td>92.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>5.3</td>\n",
       "      <td>13.275433</td>\n",
       "      <td>13.275433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-11 17:10:00</td>\n",
       "      <td>30</td>\n",
       "      <td>19.89</td>\n",
       "      <td>46.693333</td>\n",
       "      <td>19.2</td>\n",
       "      <td>44.722500</td>\n",
       "      <td>19.79</td>\n",
       "      <td>44.790000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>45.992500</td>\n",
       "      <td>...</td>\n",
       "      <td>17.066667</td>\n",
       "      <td>45.56</td>\n",
       "      <td>6.483333</td>\n",
       "      <td>733.6</td>\n",
       "      <td>92.0</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>59.166667</td>\n",
       "      <td>5.2</td>\n",
       "      <td>18.606195</td>\n",
       "      <td>18.606195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-11 17:20:00</td>\n",
       "      <td>30</td>\n",
       "      <td>19.89</td>\n",
       "      <td>46.300000</td>\n",
       "      <td>19.2</td>\n",
       "      <td>44.626667</td>\n",
       "      <td>19.79</td>\n",
       "      <td>44.933333</td>\n",
       "      <td>18.926667</td>\n",
       "      <td>45.890000</td>\n",
       "      <td>...</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>45.50</td>\n",
       "      <td>6.366667</td>\n",
       "      <td>733.7</td>\n",
       "      <td>92.0</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>55.333333</td>\n",
       "      <td>5.1</td>\n",
       "      <td>28.642668</td>\n",
       "      <td>28.642668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-11 17:30:00</td>\n",
       "      <td>40</td>\n",
       "      <td>19.89</td>\n",
       "      <td>46.066667</td>\n",
       "      <td>19.2</td>\n",
       "      <td>44.590000</td>\n",
       "      <td>19.79</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>18.890000</td>\n",
       "      <td>45.723333</td>\n",
       "      <td>...</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>45.40</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>733.8</td>\n",
       "      <td>92.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>51.500000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>45.410389</td>\n",
       "      <td>45.410389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-11 17:40:00</td>\n",
       "      <td>40</td>\n",
       "      <td>19.89</td>\n",
       "      <td>46.333333</td>\n",
       "      <td>19.2</td>\n",
       "      <td>44.530000</td>\n",
       "      <td>19.79</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>18.890000</td>\n",
       "      <td>45.530000</td>\n",
       "      <td>...</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>45.40</td>\n",
       "      <td>6.133333</td>\n",
       "      <td>733.9</td>\n",
       "      <td>92.0</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>47.666667</td>\n",
       "      <td>4.9</td>\n",
       "      <td>10.084097</td>\n",
       "      <td>10.084097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date  lights     T1       RH_1    T2       RH_2     T3  \\\n",
       "0  2016-01-11 17:00:00      30  19.89  47.596667  19.2  44.790000  19.79   \n",
       "1  2016-01-11 17:10:00      30  19.89  46.693333  19.2  44.722500  19.79   \n",
       "2  2016-01-11 17:20:00      30  19.89  46.300000  19.2  44.626667  19.79   \n",
       "3  2016-01-11 17:30:00      40  19.89  46.066667  19.2  44.590000  19.79   \n",
       "4  2016-01-11 17:40:00      40  19.89  46.333333  19.2  44.530000  19.79   \n",
       "\n",
       "        RH_3         T4       RH_4  ...         T9   RH_9     T_out  \\\n",
       "0  44.730000  19.000000  45.566667  ...  17.033333  45.53  6.600000   \n",
       "1  44.790000  19.000000  45.992500  ...  17.066667  45.56  6.483333   \n",
       "2  44.933333  18.926667  45.890000  ...  17.000000  45.50  6.366667   \n",
       "3  45.000000  18.890000  45.723333  ...  17.000000  45.40  6.250000   \n",
       "4  45.000000  18.890000  45.530000  ...  17.000000  45.40  6.133333   \n",
       "\n",
       "   Press_mm_hg  RH_out  Windspeed  Visibility  Tdewpoint        rv1        rv2  \n",
       "0        733.5    92.0   7.000000   63.000000        5.3  13.275433  13.275433  \n",
       "1        733.6    92.0   6.666667   59.166667        5.2  18.606195  18.606195  \n",
       "2        733.7    92.0   6.333333   55.333333        5.1  28.642668  28.642668  \n",
       "3        733.8    92.0   6.000000   51.500000        5.0  45.410389  45.410389  \n",
       "4        733.9    92.0   5.666667   47.666667        4.9  10.084097  10.084097  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the add_cyclical_features function in a FunctionTransformer object can use it as part of a pipeline\n",
    "encoder_transformer = FunctionTransformer(add_cyclical_features)\n",
    "\n",
    "# The PowerTransformer makes our data more normal or standard for better use in certain statistical models. \n",
    "# It finds the best way to transform the \"Appliances\" data to make it follow a bell curve (normal distribution). \n",
    "# This can help improve the accuracy of our machine learning models.\n",
    "pt = PowerTransformer()\n",
    "pt.fit(train_data[[\"Appliances\"]])\n",
    "\n",
    "\n",
    "train_data[\"Appliances\"] = pt.transform(train_data[[\"Appliances\"]])\n",
    "\n",
    "y = train_data[\"Appliances\"]\n",
    "\n",
    "X = train_data.drop(\"Appliances\", axis=1)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a59126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a8549139",
   "metadata": {},
   "source": [
    "## DecisionTreeRegressor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a3ca36c5",
   "metadata": {},
   "source": [
    "### Bayesian Search"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3e512682",
   "metadata": {},
   "source": [
    "I use inverse because transforming predictions ensures scores align with actual data values, thereby enhancing the accuracy and interpretability of model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7009e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pipe = make_pipeline(encoder_transformer, StandardScaler(), DecisionTreeRegressor(random_state=42))\n",
    "\n",
    "# param_space = {\n",
    "#     \"dt__max_depth\": Integer(1, 20),\n",
    "#     \"dt__min_samples_split\": Real(0.001, 0.5, 'log-uniform'), \n",
    "#     \"dt__min_samples_leaf\": Real(0.001, 0.5, 'log-uniform'),  \n",
    "# }\n",
    "\n",
    "param_space = {\n",
    "    \"decisiontreeregressor__max_depth\": Integer(1, 110, prior=\"uniform\"),\n",
    "    \"decisiontreeregressor__min_samples_split\": Integer(2, 10, prior=\"uniform\"),\n",
    "    \"decisiontreeregressor__min_samples_leaf\": Integer(1, 5, prior=\"uniform\")\n",
    "    }\n",
    "# param_space = {\n",
    "#     \"decisiontreeregressor__max_depth\": Integer(1, 3, prior=\"uniform\"),\n",
    "#     \"decisiontreeregressor__min_samples_split\": Integer(2, 4, prior=\"uniform\"),\n",
    "#     \"decisiontreeregressor__min_samples_leaf\": Integer(1, 3, prior=\"uniform\")\n",
    "#     }\n",
    "\n",
    "\n",
    "scoring = make_scorer(lambda y, y_pred: mean_absolute_error(pt.inverse_transform(np.array(y).reshape(-1, 1)), pt.inverse_transform(np.array(y_pred).reshape(-1, 1))), greater_is_better=False)\n",
    "\n",
    "# Bayesian optimization\n",
    "opt = BayesSearchCV(\n",
    "    estimator=pipe,\n",
    "    search_spaces=param_space,\n",
    "    cv=5,\n",
    "    n_iter=50,  # reduce if it takes too long\n",
    "    n_jobs=-1,  # use all processors\n",
    "    scoring=scoring,\n",
    "    # scoring='neg_mean_squared_error',\n",
    "    return_train_score=True,\n",
    "    # random_state=42  # for reproducibility\n",
    ")\n",
    "\n",
    "opt.fit(X_train, y_train)\n",
    "\n",
    "# print(\"Best parameters:\")\n",
    "# print(opt.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f565070",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_scores(model, X_train, y_train, X_test, y_test):\n",
    "    train_mae = calculate_model_score(model, X_train, y_train)\n",
    "    test_mae = calculate_model_score(model, X_test, y_test)\n",
    "\n",
    "    print(f\"Training MAE: {train_mae}\")\n",
    "    print(f\"Test MAE: {test_mae}\")\n",
    "\n",
    "def convert_predictions(predictions):\n",
    "    return pt.inverse_transform(predictions.reshape(-1, 1))\n",
    "    \n",
    "def calculate_model_score(model, X, y):\n",
    "    return mean_absolute_error(convert_predictions(y.array), convert_predictions(model.predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f3004a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_search_results(bs)\n",
    "print(f\"Here the Best parameters:\")\n",
    "\n",
    "for param in opt.best_params_.keys():\n",
    "    print(f\"    {param}: {opt.best_params_[param]}\")\n",
    "\n",
    "bs_optimal_tree = opt.best_estimator_\n",
    "\n",
    "print_model_scores(bs_optimal_tree, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f7505e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date                datetime64[ns]\n",
      "lights                       int64\n",
      "T1                         float64\n",
      "RH_1                       float64\n",
      "T2                         float64\n",
      "RH_2                       float64\n",
      "T3                         float64\n",
      "RH_3                       float64\n",
      "T4                         float64\n",
      "RH_4                       float64\n",
      "T5                         float64\n",
      "RH_5                       float64\n",
      "T6                         float64\n",
      "RH_6                       float64\n",
      "T7                         float64\n",
      "RH_7                       float64\n",
      "T8                         float64\n",
      "RH_8                       float64\n",
      "T9                         float64\n",
      "RH_9                       float64\n",
      "T_out                      float64\n",
      "Press_mm_hg                float64\n",
      "RH_out                     float64\n",
      "Windspeed                  float64\n",
      "Visibility                 float64\n",
      "Tdewpoint                  float64\n",
      "rv1                        float64\n",
      "rv2                        float64\n",
      "Hour                         int32\n",
      "Day_of_week                  int32\n",
      "Month                        int32\n",
      "Week_of_year                 int64\n",
      "Hour_sin                   float64\n",
      "Hour_cos                   float64\n",
      "Day_of_week_sin            float64\n",
      "Day_of_week_cos            float64\n",
      "Month_sin                  float64\n",
      "Month_cos                  float64\n",
      "Week_of_year_sin           float64\n",
      "Week_of_year_cos           float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X_train.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e9f22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_pipe = make_pipeline(\n",
    "    encoder_transformer,\n",
    "    StandardScaler(),\n",
    "    DecisionTreeRegressor(\n",
    "        max_depth=24,\n",
    "        min_samples_leaf=5,\n",
    "        min_samples_split=10,\n",
    "        random_state=42  \n",
    "    )\n",
    ")\n",
    "\n",
    "best_model_pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred_transformed = best_model_pipe.predict(X_test)\n",
    "\n",
    "# Apply inverse transformation\n",
    "y_pred = pt.inverse_transform(y_pred_transformed.reshape(-1, 1))\n",
    "\n",
    "# Compute MAE on the original scale\n",
    "mae = mean_absolute_error(pt.inverse_transform(y_test.to_numpy().reshape(-1, 1)), y_pred)\n",
    "print('Test MAE:', mae)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9d4222",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0:1000].plot(x=\"date\", y=\"Appliances\",figsize=(10,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f1068a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a2bfdff6",
   "metadata": {},
   "source": [
    "### Building a first submission\n",
    "\n",
    "For a first submission, let's just take the average consumption for the E-scooter count of the training set, and use this value for all test samples:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ce874891",
   "metadata": {},
   "source": [
    "Create a unique filename based on timestamp:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d0ddb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_unique_filename(basename, file_ext):\n",
    "    \"\"\"Adds a timestamp to filenames for easier tracking of submissions, models, etc.\"\"\"\n",
    "    timestamp = time.strftime(\"%Y%m%d-%H%M%S\", time.localtime())\n",
    "    return basename + '_' + timestamp + '.' + file_ext"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create our pandas dataframe and write it to csv. You can submit this file to Kaggle. It is very important that your submission also has the 'Id' and 'Predicted' column, with the Ids corresponding to the index of the test dataset. Normally your test data does not get mixed when doing predictions, so this should not be a problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_kaggle_submission(model, encoder_transformer):\n",
    "#     # Load the test data\n",
    "#     kaggle_data = pd.read_csv(\"test.csv\")\n",
    "\n",
    "#     # Preprocess the kaggle_data using the encoder_transformer\n",
    "#     kaggle_data_preprocessed = encoder_transformer.transform(kaggle_data)\n",
    "#     print(kaggle_data_preprocessed.head())\n",
    "#     # kaggle_data_preprocessed = add_cyclical_features(kaggle_data)\n",
    "\n",
    "#     # Make predictions\n",
    "#     predictions = model.predict(kaggle_data_preprocessed)\n",
    "\n",
    "#     # If your model was trained on transformed target variable, apply inverse transform to the predictions\n",
    "#     predictions = pt.inverse_transform(predictions.reshape(-1, 1))\n",
    "\n",
    "#     # Create a submission DataFrame\n",
    "#     submission = pd.DataFrame(data=predictions, columns=[\"Appliances\"])\n",
    "#     submission.index.name = \"Id\"\n",
    "\n",
    "#     # Generate a unique filename\n",
    "#     name = generate_unique_filename(\"energy_consumption_submission\", \"csv\")\n",
    "\n",
    "#     # Save the submission DataFrame as a csv file\n",
    "#     submission.to_csv(name)\n",
    "#     print(\"done: \" + name)\n",
    "def write_submission_to_file(submission):\n",
    "    submission.to_csv(data_folder + generate_unique_filename(\"Erdogan_Submission\", \".csv\"), index=False)\n",
    "def convert_predictions(predictions):\n",
    "    return pt.inverse_transform(predictions.reshape(-1, 1))\n",
    "\n",
    "def generate_kaggle_submission(model):\n",
    "    kaggle_data = pd.read_csv(\"test.csv\")\n",
    "    predictions = model.predict(kaggle_data)\n",
    "    predictions = convert_predictions(predictions)\n",
    "    submission = pd.DataFrame(data=predictions, columns=[\"Appliances\"])\n",
    "    submission.reset_index(inplace=True)\n",
    "    submission = submission.rename(columns = {'index':'Id'})\n",
    "    # Generate a unique filename\n",
    "    write_submission_to_file(submission)\n",
    "    # name = generate_unique_filename(\"energy_consumption_submission\", \"csv\")\n",
    "\n",
    "    # # Save the submission DataFrame as a csv file\n",
    "    # submission.to_csv(name)\n",
    "    print(\"done: \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2051b637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done: \n"
     ]
    }
   ],
   "source": [
    "# generate_kaggle_submission(best_model_pipe, encoder_transformer)\n",
    "generate_kaggle_submission(best_model_pipe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "838af5ea",
   "metadata": {},
   "source": [
    "## TO BE REMOVED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1901220f",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_consumption = train_data[\"Appliances\"].mean()\n",
    "print(average_consumption)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f1e924d6",
   "metadata": {},
   "source": [
    "Let's put this in a numpy array with length of our test dataset. Normally, 'predictions' will be the output of your model here, instead of just creating this guess:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33166d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.full(test_data.shape[0], average_consumption)\n",
    "len(predictions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "690184b0",
   "metadata": {},
   "source": [
    "Create a unique filename based on timestamp:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3751637f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_unique_filename(basename, file_ext):\n",
    "    \"\"\"Adds a timestamp to filenames for easier tracking of submissions, models, etc.\"\"\"\n",
    "    timestamp = time.strftime(\"%Y%m%d-%H%M%S\", time.localtime())\n",
    "    return basename + '_' + timestamp + '.' + file_ext"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4be5d704",
   "metadata": {},
   "source": [
    "Let's create our pandas dataframe and write it to csv. You can submit this file to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e64b6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(data=predictions, columns=[\"Appliances\"])\n",
    "submission.index.name = \"Id\"\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426c5a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(generate_unique_filename(\"average_submission\", \"csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
